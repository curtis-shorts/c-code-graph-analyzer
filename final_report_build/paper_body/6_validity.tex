\section{Threats to Validity}
\label{sec:validity}

%\cus{reconsider this whole section once everything else is ironed out}

The ANTLR workflow hinges on the quality of the grammar file which is has proven issues as evident by the error counts in Table \ref{tab:library_metadata}. This is due to the complexity in designing a grammar file that is language-complete which necessitated it being outside the scope of this work due to time constraints. The fine-tuning of the grammar file was done with UCX as it was the code-base that was most heavily analyzed in this work to mitigate the impact to the depth-based analysis results. The resulting error rate per lines of code for UCX was able to be brought down to 0.45\%. The ANTLR error results for the other libraries were 0.39\% for OFI 0.29\% for Portals. An error rate of zero is always desirable, but all three libraries having error rates below half a percent was acceptable as it is a marginal proportion and is not believed to have influenced the overall results.

There is an ever-present concern with comparative works as to if the number of items under study is sufficient. In the case of the number of algorithms analyzed two were selected (and a third considered as detailed in Section \ref{subsec:alg_description}), in order to see if a drastic difference was noticeable. Two heuristics were also considered, MQ and WMQ, which adds an additional dimension of variation to the algorithms. The results presented in Section \ref{subsec:alg_perf} demonstrated that there was no consistent performance difference between the algorithms which indicates that a drastically different approach, such as a fundamentally different heuristic or a ML-based clustering, could be a better point for comparison. The other point of varying the number of elements under study is the number of code-bases analyzed. The primary goal of this work was to analyze HPC middlewares, of which three were analyzed to provide variety with more not being available as was noted in Section \ref{subsec:workloads}.
%More were not available for analysis as these are the only open-source HPC middleware solutions available.

In order to test the portability of the methodology beyond HPC middlewares, four additional open-souce C-based code-bases were also tested. The results of these tests were omitted from this work in order to not detract from the focus on HPC middleware libraries. The first two codes tested were HPC communication libraries as they provided tests in the same field but outside of the middlewares niche. The communication libraries selected for this study were namely the OpenMPI implementation of the MPI standard and SNL's implementation of OpenSHMEM (SOS), a shared memory library for remote direct memory accessing (RDMA). The other two codes were applications rather than libraries: LAMMPS \ref{lammps_repository}, a molecular dynamics simulator, and the Apache HTTP server \ref{apache_httpd}. The preliminary numbers confidently pointed to there being no reason to believe that the domain-specificity of the code-base used changes the outcome of the methodology with the limitation being that the codes must be written in C. The one interesting point was that the hierarchical methods used were targeted at the hierarchical code topology of UCX as that's the code-base it was developed on. This means that the results, although still valid representations, could be subject to sub-optimalities in the way the data is represented in the network diagrams. OpenMPI was one such example of this due to the relatively flat directory structure of its codebase with very few subdirectories for component separation.

The two possible points of contention directly related to design choices in the methodology were the k-value selections and the hierarchical analysis methods used. The k-value selection was determined in an ad-hoc experimental process with UCX exclusively and then applied to the other code-bases without further modification. More sophisticated methods such as an elbow-analysis of what k values resulted in diminishing returns were considered, but the resulting MQ and WMQ differences found between different k value configurations were found to only be marginal. This combined with time constraints diminished the priority of a formal k analysis as it is believed it would not effect the final results in any admissible way. As for the hierarchical techniques, there is the possibility that, as mentioned previously with the analysis of non-middleware code-bases, there are certain topologies of code structuring that benefit less from these methods. This was not the case for the codes analyzed and therefore did not effect the outcomes of the work presented, but does pose a generalization issue that would need to be addressed if this methodology were to be executed on other code-bases.

%The fundamental limitation of this work is dictated by the nature of the goal which is that no level of static analysis of the middlewares will provide insight into how they will perform on a given system. This comes back to the points made in Section \ref{sec:intro} about how static analysis of these code-bases typically follow compiler-based options as they allow the expansion of pre-processor directives. This is diametrically opposed to the goals of this work which are to deepen the users understanding of how the source code is written in order to gain insight into the architecture.

